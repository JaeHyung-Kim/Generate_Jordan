{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras dcgan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6NVcePpklb6"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "# https://neurowhai.tistory.com/273 포켓몬 빌런(dcgan)\n",
        "# https://crystalcube.co.kr/192 남녀구분 ( cnn)\n",
        "# https://neurowhai.tistory.com/158 data generator. 회전및 확대축소로 데이터셋 증대\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "images = os.listdir(\"/content/drive/My Drive/JordanDataset100x100\")\n",
        "\n",
        "for i, name in enumerate(images):\n",
        "    png = Image.open(\"/content/drive/My Drive/JordanDataset100x100/\" + name)\n",
        "    png.load()\n",
        "    \n",
        "    background = Image.new(\"RGB\", png.size, (255, 255, 255))\n",
        "    background.paste(png, mask=png.split()[3])\n",
        "    \n",
        "    background.thumbnail((32,32), Image.ANTIALIAS)\n",
        "    background.save(\"/content/drive/My Drive/JordanRGB/\" + str(i) + \".jpg\", 'JPEG', quality=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF2ZjEjUtTE-",
        "outputId": "f6afd2dc-0151-49f8-c656-f34aab9fdfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os.path\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeK5vsq9tnRS"
      },
      "source": [
        "class Gan:\n",
        "  def __init__(self, img_data):\n",
        "    img_size = img_data.shape[1]\n",
        "    channel = img_data.shape[3] if len(img_data.shape) >=4 else 1\n",
        "    \n",
        "    self.img_data = img_data\n",
        "    self.input_shape = (img_size, img_size, channel)\n",
        "    \n",
        "    self.img_rows = img_size\n",
        "    self.img_cols = img_size\n",
        "    self.channel = channel\n",
        "    self.noise_size = 100\n",
        "    \n",
        "    self.create_d()\n",
        "    self.create_g()\n",
        "    \n",
        "    optimizer = Adam(lr=0.0007)\n",
        "    self.D.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    optimizer = Adam(lr=0.00035)\n",
        "    self.D.trainable = False\n",
        "    self.AM = Sequential()\n",
        "    self.AM.add(self.G)\n",
        "    self.AM.add(self.D)\n",
        "    self.AM.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "  def create_d(self):\n",
        "    self.D = Sequential()\n",
        "    depth = 64\n",
        "    dropout = 0.2\n",
        "    self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=self.input_shape, padding='same'))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(dropout))\n",
        "    self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(dropout))\n",
        "    self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(dropout))\n",
        "    self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(dropout))\n",
        "    self.D.add(Flatten())\n",
        "    self.D.add(Dense(1))\n",
        "    self.D.add(Activation('sigmoid'))\n",
        "    self.D.summary()\n",
        "    return self.D\n",
        "  \n",
        "  def create_g(self):\n",
        "    self.G = Sequential()\n",
        "    dropout = 0.2\n",
        "    depth = 64+64+64+64\n",
        "    dim = 8\n",
        "    self.G.add(Dense(dim*dim*depth, input_dim=self.noise_size))\n",
        "    self.G.add(BatchNormalization(momentum=0.9))\n",
        "    self.G.add(Activation('relu'))\n",
        "    self.G.add(Reshape((dim, dim, depth))) \n",
        "    self.G.add(Dropout(dropout))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
        "    self.G.add(BatchNormalization(momentum=0.9))\n",
        "    self.G.add(Activation('relu'))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
        "    self.G.add(BatchNormalization(momentum=0.9))\n",
        "    self.G.add(Activation('relu'))\n",
        "    self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same')) \n",
        "    self.G.add(BatchNormalization(momentum=0.9))\n",
        "    self.G.add(Activation('relu'))\n",
        "    self.G.add(Conv2DTranspose(self.channel, 5, padding='same'))\n",
        "    self.G.add(Activation('sigmoid')) \n",
        "    self.G.summary()\n",
        "    return self.G\n",
        "  \n",
        "  def train(self, batch_size=10):\n",
        "    images_train = self.img_data[np.random.randint(0, self.img_data.shape[0], size=batch_size), :, :, :]\n",
        "\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size])\n",
        "    images_fake = self.G.predict(noise)\n",
        "  \n",
        "  \n",
        "    x = np.concatenate((images_train, images_fake))\n",
        "    y = np.ones([2*batch_size, 1])\n",
        "    y[batch_size:, :] = 0\n",
        "    self.D.trainable = True\n",
        "    d_loss = self.D.train_on_batch(x, y)\n",
        "  \n",
        "    y = np.ones([batch_size, 1])\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size])\n",
        "    self.D.trainable = False\n",
        "    a_loss = self.AM.train_on_batch(noise, y)\n",
        "  \n",
        "    return d_loss, a_loss, images_fake\n",
        "  \n",
        "  def save(self):\n",
        "    self.G.save_weights('/content/drive/My Drive/gan_g_weights.h5')\n",
        "    self.D.save_weights('/content/drive/My Drive/gan_g_weights.h5')\n",
        "  \n",
        "  def load(self):\n",
        "    if os.path.isfile('/content/drive/My Drive/gan_g_weights.h5'):\n",
        "      self.G.load_weights('/content/drive/My Drive/gan_g_weights.h5')\n",
        "      print(\"Load G from file.\")\n",
        "    if os.path.isfile('/content/drive/My Drive/gan_d_weights.h5'):\n",
        "      self.D.load_weights('/content/drive/My Drive/gan_d_weights.h5')\n",
        "      print(\"Load D from file.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUdhwcSD257l"
      },
      "source": [
        "class JordanData():\n",
        "  def __init__(self):\n",
        "    img_data_list = []\n",
        "    images = os.listdir(\"/content/drive/My Drive/JordanRGB/\")\n",
        "    \n",
        "    for path in images:\n",
        "      img = Image.open(\"/content/drive/My Drive/JordanRGB/\" + path)\n",
        "      img_data_list.append([np.array(img).astype('float32')])\n",
        "      \n",
        "    self.x_train = np.vstack(img_data_list) / 255.0\n",
        "    print(self.x_train.shape)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRgft9OW36FN"
      },
      "source": [
        "dataset = JordanData()\n",
        "x_train = dataset.x_train\n",
        "\n",
        "gan = Gan(x_train)\n",
        "gan.load()\n",
        "\n",
        "epochs = 1000\n",
        "sample_size = 10\n",
        "batch_size = 10\n",
        "train_per_epoch = x_train.shape[0] // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qrz1ztAAkUz"
      },
      "source": [
        "for epoch in range(0, epochs):\n",
        "  total_d_loss = 0.0\n",
        "  total_a_loss = 0.0\n",
        "  imgs = None\n",
        "  \n",
        "  for batch in range(0, train_per_epoch):\n",
        "    d_loss, a_loss, t_imgs = gan.train(batch_size)\n",
        "    total_d_loss += d_loss\n",
        "    total_a_loss += a_loss\n",
        "    if imgs is None:\n",
        "      imgs = t_imgs\n",
        "      \n",
        "  if epoch % 50 == 49 or epoch == epochs - 1:\n",
        "    total_d_loss /= train_per_epoch\n",
        "    total_a_loss /= train_per_epoch\n",
        "    print(\"Epoch: {}, D Loss: {}, AM Loss: {}\"\n",
        "          .format(epoch, total_d_loss, total_a_loss))\n",
        "    \n",
        "    # Show generated images.\n",
        "    fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1)) \n",
        "    for i in range(sample_size): \n",
        "      ax[i].set_axis_off()\n",
        "      ax[i].imshow(imgs[i].reshape((gan.img_rows, gan.img_cols, gan.channel)),\n",
        "                    interpolation='nearest');\n",
        "      \n",
        "    plt.show()\n",
        "    plt.close(fig);\n",
        "    # Save weights\n",
        "    gan.save()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}